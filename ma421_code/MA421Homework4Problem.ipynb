{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1T77W1EEnUQIMtnKB67nEnRc30va8pSgX","timestamp":1707162088139},{"file_id":"1vo3NYb3upG2jbgPkGdxEWuoSHI5qV_34","timestamp":1644096266310},{"file_id":"1M9x_KcZ4Rg55lNRCVX-VPezb20t6Dtmx","timestamp":1644089241588},{"file_id":"1U3nW6GAkXh88R2_AKQZHL4noA7gG8q_C","timestamp":1643919657775}],"authorship_tag":"ABX9TyPlP+0OcJJOUV7qyh8ordWN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["In this homework, you will write a python implementation of logistic regression. You will test it on two datasets.\n","First we import some libraries that we need."],"metadata":{"id":"HnzRlaQaW6y1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Szla9qyoPuqg"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["We consider a real-world dataset. [The Bank Marketing Data Set](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing#) is available at UCI's Machine Learning Repository. Colab can read this dataset directly from [GitHub](https://github.com/madmashup/targeted-marketing-predictive-engine) using pandas package: pd.read_csv. The data is in the DataFrame format."],"metadata":{"id":"ef5x5LENm7_s"}},{"cell_type":"code","source":["url = 'https://raw.githubusercontent.com/madmashup/targeted-marketing-predictive-engine/master/banking.csv'\n","data = pd.read_csv(url)\n","print(data.shape)\n","print(list(data.columns))"],"metadata":{"id":"T5vKPwXfYgLV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708099573254,"user_tz":300,"elapsed":926,"user":{"displayName":"q ye","userId":"05612869899851643433"}},"outputId":"43514546-c72a-4ba2-f27f-8c35d63ddd60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(41188, 21)\n","['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'y']\n"]}]},{"cell_type":"markdown","source":["This dataset is pretty large and cause my machine to crash. I remove some fileds using data.drop. [This Webpage](https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8) has a good description of this dataset. The field \"y\" is the label denoting whether a custormer subscribes to a term deposit.\n","\n","Note that you are not allowed to use any existing model such as those used in the above Webpage for this homework."],"metadata":{"id":"UG9UWfJ8n2Jr"}},{"cell_type":"code","source":["cat_vars=['default','education','contact','month','day_of_week',]\n","data=data.drop(cat_vars, axis=1)\n","print(list(data.columns))\n","print(data.shape)"],"metadata":{"id":"pGiNyyIsvUw-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708099579593,"user_tz":300,"elapsed":155,"user":{"displayName":"q ye","userId":"05612869899851643433"}},"outputId":"54ba3f61-751a-4ce7-a341-bbfa1ea2fb35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['age', 'job', 'marital', 'housing', 'loan', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'y']\n","(41188, 16)\n"]}]},{"cell_type":"markdown","source":["Some data columns have k class labels. This is best represented as k columns (i.e one-hot encoding)."],"metadata":{"id":"OVSJRTDeoHNj"}},{"cell_type":"code","source":["cat_vars=['job','marital','housing','loan','poutcome']\n","for va in cat_vars:\n","    #cat_pre='var'+'_'+var\n","    print(va)\n","    #print(data[va])\n","    cat_list = pd.get_dummies(data[va])\n","    data1=pd.concat([data,cat_list], axis=1)\n","    data=data1.drop(va, axis=1)\n","    #print(list(cat_list.columns))\n","    #print(list(data.columns))\n","    #print(data.shape)\n","\n","print(data.shape)\n","print(list(data.columns))\n"],"metadata":{"id":"du0e-Dhyg2FV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708099613588,"user_tz":300,"elapsed":130,"user":{"displayName":"q ye","userId":"05612869899851643433"}},"outputId":"d27bdad6-b869-43d2-e757-728d4924cf06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["job\n","marital\n","housing\n","loan\n","poutcome\n","(41188, 36)\n","['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'y', 'admin.', 'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed', 'services', 'student', 'technician', 'unemployed', 'unknown', 'divorced', 'married', 'single', 'unknown', 'no', 'unknown', 'yes', 'no', 'unknown', 'yes', 'failure', 'nonexistent', 'success']\n"]}]},{"cell_type":"markdown","source":["We now split the data into input data X and the label y. We covert them to numpy and split them into training and testing datasets with 30% for testing."],"metadata":{"id":"NazsRFZmpIuD"}},{"cell_type":"code","source":["X = data.loc[:, data.columns != 'y']\n","y = data.loc[:, data.columns == 'y']\n","columns = X.columns\n","X=X.to_numpy()\n","y=y.to_numpy()\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n","\n","print(X_train.shape)\n","print(X_test.shape)\n","print(columns)"],"metadata":{"id":"u2kDuXGHtBdB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708099689366,"user_tz":300,"elapsed":212,"user":{"displayName":"q ye","userId":"05612869899851643433"}},"outputId":"ffd5b689-e443-4ca0-b0ab-fc54967166f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(28831, 35)\n","(12357, 35)\n","Index(['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate',\n","       'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'admin.',\n","       'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired',\n","       'self-employed', 'services', 'student', 'technician', 'unemployed',\n","       'unknown', 'divorced', 'married', 'single', 'unknown', 'no', 'unknown',\n","       'yes', 'no', 'unknown', 'yes', 'failure', 'nonexistent', 'success'],\n","      dtype='object')\n"]}]},{"cell_type":"markdown","source":["Now, train and test as before. You should get a training accuracy around 90%."],"metadata":{"id":"ngDOmRz9pxyR"}},{"cell_type":"code","source":["w = np.random.rand(X_train.shape[1],1)\n","b = 0\n","w, b, loss = train(w, b, X_train, y_train, iter=200, lr=0.1)\n","plt.figure()\n","plt.plot(loss)\n","\n","#training accuracy\n","y_hat = model(w,b,X_train)\n","accuracy(np.squeeze(y_train), predict(y_hat))"],"metadata":{"id":"1APudSaBd-I5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","We compute the confusion matrix for this binary classification as a better metric for accuracy. See [this PAGE](https://machinelearningmastery.com/confusion-matrix-machine-learning/) for a description. To compute the confusion matrix, you may use the confusion_matrix function from the scikit-learn package by involking\n","\n","from sklearn.metrics import confusion_matrix\n","\n","Now test your model on the testing dataset by checking the test accuracy and the confusion matrix. Don't forget to discuss the results."],"metadata":{"id":"5dxeYyy_ggF6"}},{"cell_type":"code","source":["z = model(w,b,X_test)\n","y_test=np.squeeze(y_test)\n","acc = accuracy(y_test, predict(z))\n","print(acc)\n","\n","print(np.sum(y_test),np.sum(1-y_test))\n","from sklearn.metrics import confusion_matrix\n","\n","results = confusion_matrix(y_test, predict(np.squeeze(z)))\n","print(results)"],"metadata":{"id":"ewcOQrefhp3q"},"execution_count":null,"outputs":[]}]}